{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a42fc278",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7bfcfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "class DistilBertVectorizer:\n",
    "    model_cache = {}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 128\n",
    "\n",
    "    def transform(self, texts):\n",
    "        try:\n",
    "            tokens = [self.tokenizer.encode(text, max_length=512, truncation=True) for text in texts]\n",
    "            embeddings = [self.model(torch.tensor([token]).to(self.device))[0][0][0].detach().cpu().numpy() for token in tokens]\n",
    "            return np.array(embeddings)\n",
    "        except:\n",
    "            print('Error in transform.')\n",
    "\n",
    "    def process_batches(self, texts, batch_size):\n",
    "        try:\n",
    "            num_batches = len(texts) // batch_size + 1\n",
    "            embeddings = []\n",
    "            for i in range(num_batches):\n",
    "                batch = texts[i * batch_size: (i + 1) * batch_size]\n",
    "                batch_embeddings = self.transform(batch)\n",
    "                embeddings.append(batch_embeddings)\n",
    "        except:\n",
    "            print('Error in process_batches.')\n",
    "        return np.concatenate(embeddings)\n",
    "\n",
    "    def get_model(self):\n",
    "        try:\n",
    "            model_name = 'distilbert-base-multilingual-cased'\n",
    "            if model_name in self.model_cache:\n",
    "                return self.model_cache[model_name]\n",
    "            else:\n",
    "                model = DistilBertModel.from_pretrained(model_name)\n",
    "                self.model_cache[model_name] = model\n",
    "                return model\n",
    "        except:\n",
    "            print('Error in get_model.')\n",
    "\n",
    "    def generate_embeddings(self, texts):\n",
    "        try:\n",
    "            tokens = [self.tokenizer.encode(text, max_length=512, truncation=True) for text in texts]\n",
    "            embeddings = []\n",
    "            for token in tokens:\n",
    "                token_tensor = torch.tensor([token]).to(self.device)\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(token_tensor)\n",
    "                embedding = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()\n",
    "                embeddings.append(embedding)\n",
    "            return np.array(embeddings)\n",
    "        except:\n",
    "            print('Error in generate_embeddings.')\n",
    "\n",
    "    def main(self):\n",
    "        try:\n",
    "            try:\n",
    "                resume_df = pd.read_csv('../bd/tp_one_resume.csv')\n",
    "                vacancies_df = pd.read_csv('../bd/tp_all_vacancies.csv')\n",
    "                vacancies_df = vacancies_df[:2000]\n",
    "            except:\n",
    "                print('Error : Ошибка при чтении file.csv.')\n",
    "                return -1\n",
    "\n",
    "            # на тот случай если мало мощностей\n",
    "            vacancy_desc_embeddings = self.process_batches(vacancies_df['description'].tolist(), self.batch_size)\n",
    "            resume_desc_embeddings = self.process_batches(resume_df['INF'].tolist(), self.batch_size)\n",
    "            vacancy_title_embeddings = self.process_batches(vacancies_df['name'].tolist(), self.batch_size)\n",
    "            resume_title_embeddings = self.process_batches(resume_df['name'].tolist(), self.batch_size)\n",
    "\n",
    "            # на тот случай если достаточно мощностей и маленький сет\n",
    "            # vacancy_desc_embeddings = self.generate_embeddings(vacancies_df['description'].tolist())\n",
    "            # resume_desc_embeddings = self.generate_embeddings(resume_df['description'].tolist())\n",
    "            # vacancy_title_embeddings = self.generate_embeddings(vacancies_df['name'].tolist())\n",
    "            # resume_title_embeddings = self.generate_embeddings(resume_df['name'].tolist())\n",
    "\n",
    "            alpha = 0.2\n",
    "            vacancy_embeddings = alpha * normalize(vacancy_desc_embeddings) + (1 - alpha) * normalize(vacancy_title_embeddings)\n",
    "            resume_embeddings = alpha * normalize(resume_desc_embeddings) + (1 - alpha) * normalize(resume_title_embeddings)\n",
    "            cos_sim = cosine_similarity(resume_embeddings, vacancy_embeddings)\n",
    "            top_vacancy_indices = cos_sim.argsort()[0][::-1][:10]\n",
    "            top_vacancies = vacancies_df.loc[top_vacancy_indices].reset_index(drop=True)\n",
    "            top_vacancies = top_vacancies.assign(similarity=cos_sim[0][top_vacancy_indices])\n",
    "\n",
    "            print(\"Top 10 vacancies:\")\n",
    "            top_vacancies['resume_url'] = resume_df.get('link')[0]\n",
    "            top_vacancies['tittle_resume'] = resume_df.get('name')[0]\n",
    "            top_vacancies = top_vacancies[['id', 'name', 'similarity', 'tittle_resume', 'alternate_url', 'resume_url']]\n",
    "            print(top_vacancies)\n",
    "            top_vacancies = top_vacancies[['name', 'similarity', 'tittle_resume', 'alternate_url', 'resume_url']]\n",
    "            # top_vacancies.to_csv('./AnalysisVR/bd_bot/distilbert.csv')\n",
    "            top_vacancies.to_csv('distilbert.csv')\n",
    "            top_vacancies.to_csv('../Front/bd/distilbert.csv')\n",
    "            return top_vacancies\n",
    "        except:\n",
    "            print('Error : Ошибка при чтении main.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06b580c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 vacancies:\n",
      "         id                                               name  similarity  \\\n",
      "0  82343285                                   Java-разработчик    0.995752   \n",
      "1  81360879                                   Java-разработчик    0.994078   \n",
      "2  79178095                                   Java-разработчик    0.992078   \n",
      "3  81407819                Java разработчик (импортозамещение)    0.988327   \n",
      "4  81619446                         Java-разработчик (backend)    0.988223   \n",
      "5  81251169  Java Developer / Java разработчик (Middle, Mid...    0.986510   \n",
      "6  81524864                             Разработчик JavaScript    0.985248   \n",
      "7  81512723                                 Python-разработчик    0.984622   \n",
      "8  81362339                             JavaScript разработчик    0.984250   \n",
      "9  80804168                           Инженер-программист Java    0.983983   \n",
      "\n",
      "      tittle_resume                   alternate_url  \\\n",
      "0  Java-разработчик  https://hh.ru/vacancy/82343285   \n",
      "1  Java-разработчик  https://hh.ru/vacancy/81360879   \n",
      "2  Java-разработчик  https://hh.ru/vacancy/79178095   \n",
      "3  Java-разработчик  https://hh.ru/vacancy/81407819   \n",
      "4  Java-разработчик  https://hh.ru/vacancy/81619446   \n",
      "5  Java-разработчик  https://hh.ru/vacancy/81251169   \n",
      "6  Java-разработчик  https://hh.ru/vacancy/81524864   \n",
      "7  Java-разработчик  https://hh.ru/vacancy/81512723   \n",
      "8  Java-разработчик  https://hh.ru/vacancy/81362339   \n",
      "9  Java-разработчик  https://hh.ru/vacancy/80804168   \n",
      "\n",
      "                             resume_url  \n",
      "0  https://gorodrabot.ru/resume/5334430  \n",
      "1  https://gorodrabot.ru/resume/5334430  \n",
      "2  https://gorodrabot.ru/resume/5334430  \n",
      "3  https://gorodrabot.ru/resume/5334430  \n",
      "4  https://gorodrabot.ru/resume/5334430  \n",
      "5  https://gorodrabot.ru/resume/5334430  \n",
      "6  https://gorodrabot.ru/resume/5334430  \n",
      "7  https://gorodrabot.ru/resume/5334430  \n",
      "8  https://gorodrabot.ru/resume/5334430  \n",
      "9  https://gorodrabot.ru/resume/5334430  \n",
      "Error : Ошибка при чтении main.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tvp = DistilBertVectorizer()\n",
    "    top_vacancies=tvp.main()\n",
    "    print(top_vacancies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05bee85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
